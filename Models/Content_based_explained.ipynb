{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-Based Recommendation\n",
    "This notebook implements a simple recommendation system for courses at Aalto University. \n",
    "The method being used is content-based recommendation, which is one of the two most common recommendation methods. The other being collaberative filtering.  \n",
    " \n",
    "Content based models use information about the items, in our case the courses, and the current user, in our case a student. It then combines this information to give the recommendation. \n",
    "It has been shown to work pretty well and an advantage is that we only need data on the courses and the current user, not about other users.\n",
    "On the other hand, this means that the amount of data is limited and it is hard to suggest a diverse range of items. \n",
    "\n",
    "The code was partly inspired by https://www.datacamp.com/community/tutorials/recommender-systems-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will go through the code step-by-step. See Content-based_clean for a more functional approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first import and analyze the data. \n",
    "We use the library Pandas for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of courses: 1212 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>additionalInformation</th>\n",
       "      <th>assesmentMethods</th>\n",
       "      <th>availableEnglish</th>\n",
       "      <th>cefrLevel</th>\n",
       "      <th>code</th>\n",
       "      <th>content</th>\n",
       "      <th>courseStatus</th>\n",
       "      <th>courseUnitId</th>\n",
       "      <th>credits</th>\n",
       "      <th>...</th>\n",
       "      <th>prerequisities</th>\n",
       "      <th>registration</th>\n",
       "      <th>startDate</th>\n",
       "      <th>substitutes</th>\n",
       "      <th>teacherInCharge</th>\n",
       "      <th>teachers</th>\n",
       "      <th>teachingPeriod</th>\n",
       "      <th>type</th>\n",
       "      <th>workload</th>\n",
       "      <th>name_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Compulsory attendance in all class sessions an...</td>\n",
       "      <td>100 % assignments (group and individual)</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>20E99904</td>\n",
       "      <td>The course consists of an applied, real-life p...</td>\n",
       "      <td>Mandatory course in the Master¿s programs of B...</td>\n",
       "      <td>1125574316</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>Most Master¿s Programme studies have to be com...</td>\n",
       "      <td>via WebOodi.</td>\n",
       "      <td>2018-09-19</td>\n",
       "      <td>Students can replace this capstone course by p...</td>\n",
       "      <td>Perttu KähäriNina GranqvistPaulina JunniGregor...</td>\n",
       "      <td>['Perttu Kähäri', 'Laura Peni', 'Pekka Pälli',...</td>\n",
       "      <td>Periods I-II Töölö campus, periods IV-V Otanie...</td>\n",
       "      <td>course</td>\n",
       "      <td>Contact teaching :10-15 h (incl. closing semin...</td>\n",
       "      <td>capstone: business development project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The minimum number of participants is 20</td>\n",
       "      <td>Learning diaries 50%Take-home exam 50%</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>21C00150</td>\n",
       "      <td>This introductory course gives a basic underst...</td>\n",
       "      <td>Degree Elective</td>\n",
       "      <td>1130843834</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Via WebOodi</td>\n",
       "      <td>2019-02-27</td>\n",
       "      <td></td>\n",
       "      <td>DSc Christa Uusi-Rauva, Professor Ingmar Björkman</td>\n",
       "      <td>['Alice Wickström', 'Ingmar Björkman']</td>\n",
       "      <td>2018-2019; IV, Otaniemi Campus 2019-2020: no t...</td>\n",
       "      <td>course</td>\n",
       "      <td>Lectures: 33 hoursLearning diaries: 24 hoursTa...</td>\n",
       "      <td>introduction to business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Max. 100 students. Priority for management stu...</td>\n",
       "      <td>Final exam: 40%Assignments: 30%Learning diary:...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>21C00350</td>\n",
       "      <td>Throughout this course, we will be covering di...</td>\n",
       "      <td>Bachelor: Management HR specialization area Co...</td>\n",
       "      <td>1125857456</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>It is recommended that the students have basic...</td>\n",
       "      <td>WebOodi</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>21C00300 Henkilöstöjohtaminen</td>\n",
       "      <td>Kathrin Sele</td>\n",
       "      <td>['Kathrin Sele']</td>\n",
       "      <td>Period II (2018-2019), Otaniemi campusPeriod I...</td>\n",
       "      <td>course</td>\n",
       "      <td>Lectures 30h presence (obligatory classroom pr...</td>\n",
       "      <td>human resource management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>21C03000</td>\n",
       "      <td>The course is taught by a visiting lecturer an...</td>\n",
       "      <td>B.Sc. Management minor</td>\n",
       "      <td>1133021737</td>\n",
       "      <td>3-6</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>via WebOodi</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td></td>\n",
       "      <td>The course is taught by a visiting lecturer. 2...</td>\n",
       "      <td>['Mikko Martela']</td>\n",
       "      <td>2018-2019: III, Otaniemi campusNo teaching 201...</td>\n",
       "      <td>course</td>\n",
       "      <td></td>\n",
       "      <td>current issues in leadership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>50% reflective learning diary50% final essay exam</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>21C10000</td>\n",
       "      <td>Must know: the concepts of \"concept and contex...</td>\n",
       "      <td>Aalto-course Management minor elective course</td>\n",
       "      <td>1121603277</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>No specific prerequisites for attending the co...</td>\n",
       "      <td>Via Weboodi</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td></td>\n",
       "      <td>Esko Aho Kirsti Iivonen</td>\n",
       "      <td>['Esko Aho', 'Kirsti Iivonen']</td>\n",
       "      <td>Period III (2018-2019)Period III (2019-2020)</td>\n",
       "      <td>course</td>\n",
       "      <td>Attending lectures 24h (not compulsory but hig...</td>\n",
       "      <td>business and society</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                              additionalInformation  \\\n",
       "0     0  Compulsory attendance in all class sessions an...   \n",
       "1     1           The minimum number of participants is 20   \n",
       "2     2  Max. 100 students. Priority for management stu...   \n",
       "3     3                                                      \n",
       "4     4                                                      \n",
       "\n",
       "                                    assesmentMethods availableEnglish  \\\n",
       "0           100 % assignments (group and individual)             True   \n",
       "1             Learning diaries 50%Take-home exam 50%             True   \n",
       "2  Final exam: 40%Assignments: 30%Learning diary:...             True   \n",
       "3                                                                True   \n",
       "4  50% reflective learning diary50% final essay exam             True   \n",
       "\n",
       "  cefrLevel      code                                            content  \\\n",
       "0            20E99904  The course consists of an applied, real-life p...   \n",
       "1            21C00150  This introductory course gives a basic underst...   \n",
       "2            21C00350  Throughout this course, we will be covering di...   \n",
       "3            21C03000  The course is taught by a visiting lecturer an...   \n",
       "4            21C10000  Must know: the concepts of \"concept and contex...   \n",
       "\n",
       "                                        courseStatus courseUnitId credits  \\\n",
       "0  Mandatory course in the Master¿s programs of B...   1125574316       6   \n",
       "1                                    Degree Elective   1130843834       3   \n",
       "2  Bachelor: Management HR specialization area Co...   1125857456       6   \n",
       "3                           B.Sc. Management minor     1133021737     3-6   \n",
       "4    Aalto-course Management minor elective course     1121603277       6   \n",
       "\n",
       "                    ...                    \\\n",
       "0                   ...                     \n",
       "1                   ...                     \n",
       "2                   ...                     \n",
       "3                   ...                     \n",
       "4                   ...                     \n",
       "\n",
       "                                      prerequisities  registration  \\\n",
       "0  Most Master¿s Programme studies have to be com...  via WebOodi.   \n",
       "1                                                      Via WebOodi   \n",
       "2  It is recommended that the students have basic...       WebOodi   \n",
       "3                                                      via WebOodi   \n",
       "4  No specific prerequisites for attending the co...   Via Weboodi   \n",
       "\n",
       "    startDate                                        substitutes  \\\n",
       "0  2018-09-19  Students can replace this capstone course by p...   \n",
       "1  2019-02-27                                                      \n",
       "2  2018-10-30                      21C00300 Henkilöstöjohtaminen   \n",
       "3  2019-01-09                                                      \n",
       "4  2019-01-08                                                      \n",
       "\n",
       "                                     teacherInCharge  \\\n",
       "0  Perttu KähäriNina GranqvistPaulina JunniGregor...   \n",
       "1  DSc Christa Uusi-Rauva, Professor Ingmar Björkman   \n",
       "2                                       Kathrin Sele   \n",
       "3  The course is taught by a visiting lecturer. 2...   \n",
       "4                            Esko Aho Kirsti Iivonen   \n",
       "\n",
       "                                            teachers  \\\n",
       "0  ['Perttu Kähäri', 'Laura Peni', 'Pekka Pälli',...   \n",
       "1             ['Alice Wickström', 'Ingmar Björkman']   \n",
       "2                                   ['Kathrin Sele']   \n",
       "3                                  ['Mikko Martela']   \n",
       "4                     ['Esko Aho', 'Kirsti Iivonen']   \n",
       "\n",
       "                                      teachingPeriod    type  \\\n",
       "0  Periods I-II Töölö campus, periods IV-V Otanie...  course   \n",
       "1  2018-2019; IV, Otaniemi Campus 2019-2020: no t...  course   \n",
       "2  Period II (2018-2019), Otaniemi campusPeriod I...  course   \n",
       "3  2018-2019: III, Otaniemi campusNo teaching 201...  course   \n",
       "4       Period III (2018-2019)Period III (2019-2020)  course   \n",
       "\n",
       "                                            workload  \\\n",
       "0  Contact teaching :10-15 h (incl. closing semin...   \n",
       "1  Lectures: 33 hoursLearning diaries: 24 hoursTa...   \n",
       "2  Lectures 30h presence (obligatory classroom pr...   \n",
       "3                                                      \n",
       "4  Attending lectures 24h (not compulsory but hig...   \n",
       "\n",
       "                                 name_low  \n",
       "0  capstone: business development project  \n",
       "1                introduction to business  \n",
       "2               human resource management  \n",
       "3            current issues in leadership  \n",
       "4                    business and society  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas\n",
    "import pandas as pd\n",
    "#read the course info. The courses are stored in the file filtered_courses.csv\n",
    "courses=pd.read_csv('../Data/filtered_courses.csv')\n",
    "#if an entry is empty, i.e. NaN, replace it with an empty string. This makes processing easier \n",
    "courses=courses.fillna('')\n",
    "#convert all content to strings. We do this because we will be treating everything as strings and this makes it a lot easier to work with\n",
    "courses=courses.astype(str)\n",
    "#Add a column with the name of the course lowered and stripped\n",
    "courses['name_low']=courses['name'].str.lower()\n",
    "courses['name_low']=courses['name_low'].str.strip()\n",
    "#print the number of courses and the first entries, to get a feel for the data\n",
    "print(\"Number of courses:\",len(courses),\"\\n\")\n",
    "courses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create one column per course that contains all the information we are interested in, i.e. which we will use as item information for our model \n",
    "Which columns we take into account is specified in the variable input_columns. You can change the values here! All available columns can be retrieved by courses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give the column names of the columns we want to consider\n",
    "#this can be changed!\n",
    "input_columns=['additionalInformation', 'assesmentMethods','content','courseStatus','credits','gradingScale','learningOutcomes','level','literature','organizationId','prerequisities','teacherInCharge','type','workload']\n",
    "\n",
    "#create one column that contains all info we consider per course\n",
    "courses['combined']=courses[input_columns].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we give an input, this is the topic or course the user is interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input='Artificial Intelligence'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process the user input and check whether the input is an existing course or any other term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower input to make processing easier\n",
    "user_input=user_input.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A course\n"
     ]
    }
   ],
   "source": [
    "#check if user input is a course or not\n",
    "if not courses['name_low'].str.contains(r'^%s$'%user_input).any():\n",
    "    print('Not a course')\n",
    "    #if not a course append the input to the courses dataframe. We use this structure to later compute the similarities between input and courses\n",
    "    courses=courses.append({'combined':user_input,'name_low':user_input},ignore_index=True)\n",
    "else:\n",
    "    print('A course')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF \n",
    "Now that we have the correct data in place, we want to vectorize the data. \n",
    "By vectorizing we mean giving a number to each word. So that we can calculate the similarities later by comparing those numbers.  \n",
    "As method we use tf-idf which stands for term frequency–inverse document frequency. tf-idf indicates the importance of a certain word compared to the whole corpus.   \n",
    "Tf-idf consists of two terms, the term frequency (tf) and the inverse document frequency (idf). We multiply these two terms to get the tf-idf.    \n",
    "The term frequency in its most basic form states how often word d occurs in document n. Mathematically this can be written as $|d \\in n|$  \n",
    "The inverse document frequency states how important a certain word d is in the whole corpus. For example, 'entrepreneurship' can be very indicative whereas the word 'course' isn't. This is calculated by the total number of courses, N, dived by the number of courses in which the word d occurs, mathematically this can be written as $\\frac{N}{|\\{n \\in N: d \\in n\\}|}$.  \n",
    "\n",
    "In our implementation we expand this a bit by calculating it as $log(\\frac{N}{|\\{n \\in N: d \\in n\\}|})+1$ if $|\\{n \\in N: d \\in n\\}|>0$ else $0$.  \n",
    "We add the log here because the importance of a word is not linear but more sub-linear. If word1 occurs 10 times in the corpus instead of 5 times, the relevance of that word is probably not 2 times as small. The log heavily minimizes the difference in idf between these two cases.  \n",
    "The +1 is added to distinguish between $|\\{n \\in N: d \\in n\\}|<=0$ and $\\frac{N}{|\\{n \\in N: d \\in n\\}|}$=1 since the log of 1 equals 0.  \n",
    "\n",
    "By multiplying the tf with the idf we get an importance score for every word in every course. Pay attention, that this score doesn't only depend on the word, but also on the number of occurences and length of the specific course you are looking at.    \n",
    "In theory the tf-idf will be the highest when a course only has that word d and no other course has that word d. The tf-idf is always larger or equal than zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the implementation by sklearn. This implementation comes with several tunable parameters. There is no golden standard on which values to use. I will go through some of the parameters, but it is not important to understand in order to understand the rest of this code.\n",
    "\n",
    "### Stopwords\n",
    "You can choose whether to remove stopwords. In general this is a good idea. This code uses as standard option to use the English corpus of stopwords provided by sklearn.  \n",
    "Default=english\n",
    "\n",
    "### Tokenizer\n",
    "You can give any kind of tokenizer. This means the model will do some pre-processing on the data. When adding a tokenizer, it will mostly remove punctation etc. In the tokenizer, you can also add a stemmer, which stems words, e.g. innovation and innovate will both become innov.  \n",
    "In this code one tokenizer is available, see the cell below. However, in the pre-set parameters this is not used. It really depends on the situation whether it is good to stem and tokenize, or that this generalizes too much.  \n",
    "Default=None    \n",
    "Call tokenizer by tokenize=tokenize_and_stem\n",
    "\n",
    "### Smooth_idf\n",
    "This adds one to the numerator and denominator of the idf. This prevents division by zero. \n",
    "Hence, the full formula becomes $log(\\frac{N+1}{|\\{n \\in N: d \\in n\\}|+1})+1$  \n",
    "Default=True  \n",
    "\n",
    "### Sublinear_tf\n",
    "This also makes the term frequency sublinear. Hence, the formula becomes $log(|d \\in n|)+1$    \n",
    "Again, the same logic applies as with the idf. If a word occurs 100 times or 200 times, it might doesn't make the word twice as relevant. The log minimizes the difference in tf between these two cases.    \n",
    "From experiments we concluded that it really depends on the case whether this seems to work better or not. In the final experiments this has to be tested again.    \n",
    "Default=False\n",
    "stop_words=stopwords,smooth_idf=smooth,sublinear_tf=sublin,tokenizer=tokenize\n",
    "\n",
    "### Norm\n",
    "This \n",
    "In this code we also divide by the lenght of the document, in order to normalize for documents with different lengths.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"The dog ate a sandwich and I ate a sandwich\",\n",
    "          \"The wizard transfigured a sandwich\"]\n",
    "vectorizer1 = TfidfVectorizer(stop_words='english',norm=None)\n",
    "vectorizer2 = TfidfVectorizer(stop_words='english',)\n",
    "tfidfs = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[2.81093022, 1.40546511, 2.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , 1.40546511, 1.40546511]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1.fit_transform(corpus).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.75458397, 0.37729199, 0.53689271, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.44943642, 0.6316672 , 0.6316672 ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2.fit_transform(corpus).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.449034575662326"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/2.227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2250088495967497"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.40546511/0.6316672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[6.21639532],\n",
       "        [3.81093022]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(vectorizer1.fit_transform(corpus).todense(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the stemmer and tokenizer. This is an extra feature and you don't have to understand this to use the code \n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "#create stemmer and tokenizer, to be used by tf-idf\n",
    "#copied from https://github.com/senticr/SentiCR/blob/master/SentiCR/SentiCR.py\n",
    "stemmer =SnowballStemmer(\"english\")\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stems = stem_tokens(tokens)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mostsim(user_input,indices,sim):\n",
    "    \"\"\"Get the most similar courses for the input\"\"\"\n",
    "\n",
    "    # Get index of course given title\n",
    "    idx = indices[user_input]\n",
    "\n",
    "    #Get similarity of course to all other courses\n",
    "    # structure is list of (index, similarity)\n",
    "    sim_row = list(enumerate(sim[idx]))\n",
    "\n",
    "    #sort the courses by descending score\n",
    "    sim_sorted = sorted(sim_row, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    sim_indices = [i[0] for i in sim_sorted[1:]]\n",
    "    sim_scores=[i[1] for i in sim_sorted[1:]]\n",
    "\n",
    "    return sim_indices,sim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recom_freetext(user_input,courses,input_columns=['content','name'],future=False,meas='cosine',stopwords='english',smooth=True,sublin=False,tokenize=None,norm='l2'):\n",
    "    \"\"\"\n",
    "    Give recommendations based on the user input\n",
    "    user_input: string user inputs\n",
    "    courses: DataFrame with the courses\n",
    "    input_columns: the columns of the courses dataframe we want to consider\n",
    "    future: if True only recommend courses taking place in the future\n",
    "    meas: indicates the similarity measure we use\n",
    "    stopwords: indicates which stopwords should be removed\n",
    "    smooth: whether to use smooth idf\n",
    "    sublin: whether to use sublinear TF\n",
    "    tokenize: whether to tokenize the input\n",
    "    \"\"\"\n",
    "    user_input=user_input.lower()\n",
    "    #create one column that contains all info we consider per course\n",
    "    courses['combined']=courses[input_columns].apply(lambda x: ' '.join(x), axis=1)\n",
    "    #some preprocessing on the name (title of courses)\n",
    "    courses['name_low']=courses['name'].str.lower()\n",
    "    courses['name_low']=courses['name_low'].str.strip()\n",
    "    #check if user input is a course or not\n",
    "    if not courses['name_low'].str.contains(r'^%s$'%user_input).any():\n",
    "        print('Not a course')\n",
    "        courses=courses.append({'combined':user_input,'name_low':user_input},ignore_index=True)\n",
    "    else:\n",
    "        print('A course')\n",
    "\n",
    "    #create dataframe with courses that meet the requirements \n",
    "    if future:\n",
    "        courses_req=check_startdate(courses)\n",
    "    else:\n",
    "        courses_req=courses\n",
    "\n",
    "    #define the tf-idf vectorizer\n",
    "    tfidf_all = TfidfVectorizer(stop_words=stopwords,smooth_idf=smooth,sublinear_tf=sublin,tokenizer=tokenize,norm=norm)\n",
    "    #get the tf-idf score for each word in each ontent description of each course\n",
    "    tfidf_matrix_all = tfidf_all.fit_transform(courses['combined'])\n",
    "    \n",
    "    #do the same but with only the courses that meet the requirements. However, use the vocabulary from the list of all courses\n",
    "    tfidf_req=TfidfVectorizer(use_idf=True,vocabulary=tfidf_all.vocabulary_,stop_words=stopwords,smooth_idf=smooth,sublinear_tf=sublin,tokenizer=tokenize)\n",
    "    tfidf_matrix_req=tfidf_req.fit_transform(courses_req['combined'])\n",
    "    \n",
    "    #Construct a reverse map of indices and courses\n",
    "    # we use this to map index to title and the other way around\n",
    "    indices = pd.Series(courses_req.index, index=courses_req['name_low'])\n",
    "    \n",
    "    #get the similarity scores\n",
    "    if meas=='cosine':\n",
    "        sim = linear_kernel(tfidf_matrix_req, tfidf_matrix_req)\n",
    "    sim_indices,sim_scores=get_mostsim(user_input,indices,sim)\n",
    "    urls=['https://oodi.aalto.fi/a/opintjakstied.jsp?Kieli=6&html=1&Tunniste='+courses_req['code'].iloc[i] for i in sim_indices[:10]]\n",
    "    return courses_req['name'].iloc[sim_indices[:10]],urls,sim_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recom(user_input):\n",
    "    df=pd.read_csv('../Data/filtered_courses.csv')\n",
    "    df['content']=df['content'].fillna('')\n",
    "    course_titles,urls,similarities=recom_freetext(user_input,df)\n",
    "    return course_titles, urls,similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A course\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(388              Introduction to Artificial Intelligence\n",
       " 402                              Declarative Programming\n",
       " 486                            Systems of Representation\n",
       " 1195                     Art and Artificial Intelligence\n",
       " 401                   Machine Learning: Basic Principles\n",
       " 64                            Capstone course: Marketing\n",
       " 673                               Reinforcement learning\n",
       " 708                            AI in health technologies\n",
       " 430     Machine Learning: Advanced Probabilistic Methods\n",
       " 161                      Capstone: Business Intelligence\n",
       " Name: name, dtype: object,\n",
       " ['https://oodi.aalto.fi/a/opintjakstied.jsp?Kieli=6&html=1&Tunniste=CS-C1000',\n",
       "  'https://oodi.aalto.fi/a/opintjakstied.jsp?Kieli=6&html=1&Tunniste=CS-E3220',\n",
       "  'https://oodi.aalto.fi/a/opintjakstied.jsp?Kieli=6&html=1&Tunniste=DOM-E5003',\n",
       "  'https://oodi.aalto.fi/a/opintjakstied.jsp?Kieli=6&html=1&Tunniste=UWAS-C0025',\n",
       "  'https://oodi.aalto.fi/a/opintjakstied.jsp?Kieli=6&html=1&Tunniste=CS-E3210',\n",
       "  'https://oodi.aalto.fi/a/opintjakstied.jsp?Kieli=6&html=1&Tunniste=23E99906',\n",
       "  'https://oodi.aalto.fi/a/opintjakstied.jsp?Kieli=6&html=1&Tunniste=ELEC-E8125',\n",
       "  'https://oodi.aalto.fi/a/opintjakstied.jsp?Kieli=6&html=1&Tunniste=ELEC-E8739',\n",
       "  'https://oodi.aalto.fi/a/opintjakstied.jsp?Kieli=6&html=1&Tunniste=CS-E4820',\n",
       "  'https://oodi.aalto.fi/a/opintjakstied.jsp?Kieli=6&html=1&Tunniste=57E00500'],\n",
       " [0.3074303568350946,\n",
       "  0.2973289310541618,\n",
       "  0.24480839390016937,\n",
       "  0.24345928185801885,\n",
       "  0.21755776975530888,\n",
       "  0.20931416902993238,\n",
       "  0.20590661999135695,\n",
       "  0.20588526616434621,\n",
       "  0.2007120705112007,\n",
       "  0.19336094787445735])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recom('artificial intelligence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
