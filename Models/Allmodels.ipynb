{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based, collaberative and hybrid recommender for courses at Aalto University\n",
    "This notebook shows how a simple content-based, collaberative and hybrid recommender can be made for real-data of courses. \n",
    "We use data of course descriptions and courses taken by students in the past\n",
    "The output is a file with the most K similair courses to all D courses. Hence, it is a DxK matrix.\n",
    "\n",
    "**Note: this notebook doesn't input any data, since this is private data. It only shows how to make the model.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define variables\n",
    "Set these, fitting to your datasets and file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_courses=\"\"\n",
    "delimiter_courses=\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coursecode_col=\"\"\n",
    "coursename_col=\"\"\n",
    "coursedescript_col=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_hist=\"\"\n",
    "delimiter_hist=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_studentid_col=\"\"\n",
    "hist_coursecode_col=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_hist_bin=\"../Data/history_binary.csv\"\n",
    "path_results=\"../Data/Results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load course data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load course description data\n",
    "#this data is in this script only used to retrieve the matching names from the course codes. \n",
    "df_courses=pd.read_csv(file_path_courses,delimiter=delimiter_courses)\n",
    "df_courses=df_courses.rename(columns={coursecode_col:\"code\",coursename_col:\"name\",coursedescript_col:\"description\"})\n",
    "df_courses=df_courses.set_index(\"code\",drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe with all the matching codes and names in course description data\n",
    "df_codename=df_courses[[\"code\",\"name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #read the course description data\n",
    "# df_courses.set_index('Code',inplace=True)\n",
    "# df_courses.index.name='code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of courses in course description data:\",df_codename.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load csv with historical data\n",
    "df_hist=pd.read_csv(file_path_hist,delimiter=delimiter_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of courses taken by all students:\",len(df_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist=df_hist[[hist_studentid_col,hist_coursecode_col]]\n",
    "df_hist.columns=[\"ID\",\"code\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create matrix indicating which students have taken which courses\n",
    "create the DxN matrix where dataframe of size DxN where D is number of courses and N number of users\n",
    "binary entries, 1 indicating user has token that course, 0 indicating student has not taken that course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: this takes rather long to create, so execute once, and then use the cell below to load the file\n",
    "\n",
    "#merge dataframes such that only courses are left which are both in the historical and course description data\n",
    "df_hist_both = pd.merge(df_hist, df_codename, how='inner', on=['code'])\n",
    "\n",
    "#crashes when doing with too large dataset\n",
    "df_hist_bin=pd.crosstab(df_hist_both[\"code\"], df_hist_both[\"ID\"])\n",
    "df_hist_bin.to_csv(file_path_hist_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #read the csv history_dataframe\n",
    "# #this is a DxN matrix where D is number of courses and N number of users\n",
    "# #binary entries, 1 indicating user has token that course, 0 indicating student has not taken that course.\n",
    "# df_history=pd.read_csv(file_path_hist_bin,index_col=\"code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define similarity measures\n",
    "For content, collaberative and hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_measure_content (df,input_columns,sim='cos',stopwords='english',smooth=True,sublin=False,tokenize=None):\n",
    "    \"\"\"\n",
    "    Calculate the similarity between every entry of a dataframe\n",
    "    df: the dataframe\n",
    "    sim: the similarity measure. Now only implemented for cosine similarity.\n",
    "    input_columns: the columns of the courses dataframe we want to consider\n",
    "    stopwords: indicates which stopwords should be removed\n",
    "    smooth: whether to use smooth idf\n",
    "    sublin: whether to use sublinear TF\n",
    "    tokenize: whether to tokenize the input\n",
    "    \"\"\"\n",
    "    \n",
    "    #create a new column which has all the columns we are interested in as one string\n",
    "    df_courses['combined']=df[input_columns].apply(lambda x: ' '.join(x), axis=1)\n",
    "    \n",
    "    #define the tf-idf vectorizer\n",
    "    tfidf_all = TfidfVectorizer(stop_words=stopwords,smooth_idf=smooth,sublinear_tf=sublin,tokenizer=tokenize)\n",
    "    #get the tf-idf score for each word in each ontent description of each course\n",
    "    tfidf_matrix_all = tfidf_all.fit_transform(df['combined'])\n",
    "    \n",
    "    #calculate the cosine similarity\n",
    "    if sim=='cos':\n",
    "        sim_matrix=cosine_similarity(tfidf_matrix_all,tfidf_matrix_all)\n",
    "    \n",
    "    return pd.DataFrame(data=sim_matrix, index= df.index, columns= df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_measure_collaberative (df, norm=True,sim='cos'):\n",
    "    \"\"\"\n",
    "    Calculate the similarity between every entry of a dataframe\n",
    "    df: the dataframe\n",
    "    norm: whether to normalize the dataframe\n",
    "    sim: the similarity measure. Now only implemented for cosine similarity and cooccurence. \n",
    "    \"\"\"\n",
    "    \n",
    "    if norm:\n",
    "        #normalize for the fact that some users have taken more courses than others. \n",
    "        #the resulting dataframe is not binary, but contains values between 0 and 1. \n",
    "        magnitude=np.sqrt(np.square(np.sum(df,axis=0)))\n",
    "        df=df.divide(magnitude)\n",
    "    \n",
    "    #it is a rather large matrix, so much faster when converting it into a sparse matrix\n",
    "    mat_df=sparse.csr_matrix(df)\n",
    "    if sim=='cos':\n",
    "        sim_matrix=cosine_similarity(mat_df,mat_df)\n",
    "    if sim=='cooccur':\n",
    "        sim_matrix=(mat_df@mat_df.T).todense()\n",
    "    \n",
    "    #df.index is here the course codes\n",
    "    return pd.DataFrame(data=sim_matrix, index= df.index, columns= df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_measure_hybrid (df_content,df_collab, input_columns,norm=True,sim_con='cos',sim_col='cos',stopwords='english',smooth=True,sublin=False,tokenize=None):\n",
    "    #sadly, the concat doesn't work too well when content and collab have differen indices and columns, thus only do the hybrid for courses that appear in both datasets\n",
    "    df_content_both=df_content[df_content.index.isin(df_collab.index)]\n",
    "    df_sim_content=get_sim_measure_content(df_content_both,input_columns=input_columns,sim=sim_con,stopwords=stopwords,smooth=smooth,sublin=sublin,tokenize=tokenize)\n",
    "    df_sim_collab=get_sim_measure_collaberative(df_collab,norm=norm,sim=sim_col)\n",
    "    df_sim_hybrid=pd.concat([df_sim_content,df_sim_collab],join='outer').groupby(level=0).sum()\n",
    "    \n",
    "    return df_sim_hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract most similar courses for each course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mostsimilar(user_input,df):\n",
    "    \"\"\"\n",
    "    Get the courses sorted on similarity to the input course\n",
    "    user_input: the course code of the course we are interested in\n",
    "    df: dataframe with similarity scores\n",
    "    \"\"\"\n",
    "\n",
    "    #Get similarity of course to all other courses\n",
    "    # structure is list of (index, similarity)\n",
    "    input_row = list(enumerate(df.loc[user_input]))\n",
    "\n",
    "    #sort the courses by descending score\n",
    "    courses_sorted = df.loc[user_input].sort_values(ascending=False)\n",
    "    \n",
    "    highest_codes=courses_sorted.index\n",
    "    highest_scores=list(courses_sorted)\n",
    "    \n",
    "\n",
    "    return highest_codes,highest_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostsim_allcourses(df_sim,indices,number_courses=3):\n",
    "    \"\"\"\n",
    "    Create a dataframe which has the most similar courses to each course in the input dataframe\n",
    "    df_sim: dataframe with similarity between all courses\n",
    "    indices: dataframe which has the code and name of all courses of df_sim\n",
    "    number_courses: the amount of most similar courses we want to return for each course.  \n",
    "    \"\"\"\n",
    "\n",
    "    k=number_courses\n",
    "    #use the indices dataframe as basis\n",
    "    df_mostsim=indices.copy()\n",
    "    #add a column for every similar course\n",
    "    columns_sim=['sim'+str(i) for i in range(1,k+1)]\n",
    "    #set columns to be the original plus the similarity columns\n",
    "    df_mostsim=df_mostsim.reindex(columns=[*df_mostsim.columns.tolist()+columns_sim])\n",
    "\n",
    "    #for every course\n",
    "    for i in df_mostsim.index:\n",
    "        #get the similar courses\n",
    "        sim_codes,sim_scores=get_mostsimilar(i,df_sim)\n",
    "        #add the highest k to the dataframe\n",
    "        #sim_codes[0] is the input course, so don't include that\n",
    "        df_mostsim.loc[i,columns_sim]=df_mostsim.loc[sim_codes[range(1,k+1)]]['name'].values\n",
    "    df_mostsim.drop(columns=['code'],inplace=True)\n",
    "    return df_mostsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simall_collaberative=mostsim_allcourses(get_sim_measure_collaberative(df_hist_bin),df_codename[df_codename.code.isin(df_hist.code)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simall_content=mostsim_allcourses(get_sim_measure_content(df_courses,[\"name\",\"description\"]),df_codename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simall_hybrid=mostsim_allcourses(get_sim_measure_hybrid(df_courses,df_hist_bin,[\"name\",\"description\"]),df_codename[df_codename.code.isin(df_hist.code)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simall_hybrid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simall_hybrid.to_csv(path_results+\"df_simcourses_hybrid.csv\")\n",
    "df_simall_content.to_csv(path_results+\"df_simcourses_content.csv\")\n",
    "df_simall_collaberative.to_csv(path_results+\"df_simcourses_collaberative.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
